{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwritten_digits_GANs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaashaJoshi/generating-handwritten-digits-GAN/blob/master/handwritten_digits_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44VuXwlRlb_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD9h_8c-oKl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(train_imgs, train_labels), (test_imgs, test_labels)=mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLM4q5sSocbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train: ', train_imgs.shape, train_labels.shape)\n",
        "print('Test: ', test_imgs.shape, test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZw382oeow2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(test_imgs[0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGq1Sj6upFRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(test_imgs[10], cmap='gray_r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSj9Cn58pUnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(25):\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(train_imgs[i], cmap='gray_r')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sAzgrkDqH0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DISCRIMINATOR MODEL\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        " \n",
        "def define_discriminator(in_shape=(28,28,1)):\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "'''\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=(28, 28, 1)), \n",
        "    keras.layers.LeakyReLU(alpha=0.2), \n",
        "    keras.layers.Dropout(0.4), \n",
        "    keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'), \n",
        "    keras.layers.LeakyReLU(alpha=0.2), \n",
        "    keras.layers.Dropout(0.4), \n",
        "    keras.layers.Flatten(), \n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5), \n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5MYUu1PtTvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST training images\n",
        "def load_real_samples():\n",
        "  (train_imgs, _), (_, _)=mnist.load_data()\n",
        "  train_img_samples=np.expand_dims(train_imgs, axis=-1)\n",
        "  train_img_samples=train_img_samples.astype('float32')/255\n",
        "  return train_img_samples\n",
        "\n",
        "# Select random real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "  x=np.random.randint(0, dataset.shape[0], n_samples)\n",
        "  train_img_samples=dataset[x]\n",
        "  train_label_samples=np.ones((n_samples, 1))\n",
        "  return train_img_samples, train_label_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYpb0slLuonT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select random fake samples\n",
        "def generate_fake_samples(n_samples):\n",
        "  train_img_samples=np.random.rand(28*28*n_samples)\n",
        "  train_img_samples=train_img_samples.reshape((n_samples, 28, 28, 1))\n",
        "  train_label_samples=np.zeros((n_samples, 1))\n",
        "  return train_img_samples, train_label_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5VbZzD7yvJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN DISCRIMINATOR MODEL\n",
        "def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n",
        "  half_batch=int(n_batch/2)\n",
        "  \n",
        "  for i in range(n_iter):\n",
        "    img_real, label_real=generate_real_samples(dataset, half_batch)\n",
        "    _, real_accuracy=model.train_on_batch(img_real, label_real)\n",
        "    \n",
        "    img_fake, label_fake=generate_fake_samples(half_batch)\n",
        "    _, fake_accuracy=model.train_on_batch(img_fake, label_fake)\n",
        "    \n",
        "    print('{} Real: {}% Fake: {}%'.format(i+1, real_accuracy*100, fake_accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bwzH-uf055_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=define_discriminator()\n",
        "dataset=load_real_samples()\n",
        "train_discriminator(model, dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_oFPcLM1E-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "keras.utils.plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7jgABS_56g5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GENERATOR MODEL\n",
        "\n",
        "def define_generator(latent_dim):\n",
        "  model=Sequential()\n",
        "  n_nodes=128*7*7\n",
        "  model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((7, 7, 128)))\n",
        "  model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Conv2DTranspose(1, (7, 7), activation='sigmoid', padding='same'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBOtb0B9Ju9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim=100   #100 element vector; can be 10, 50, 500 etc.\n",
        "model=define_generator(latent_dim)\n",
        "model.summary()\n",
        "keras.utils.plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuEgLi-xKShk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "  latent_points=np.random.randn(latent_dim*n_samples)\n",
        "  latent_points=latent_points.reshape(n_samples, latent_dim)\n",
        "  return latent_points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHdieQOLtqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "  latent_points=generate_latent_points(latent_dim, n_samples)\n",
        "  img_fake_samples=g_model.predict(latent_points)\n",
        "  label_fake_samples=np.zeros((n_samples, 1))\n",
        "  return img_fake_samples, label_fake_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHBHPrlYMLgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_samples=25\n",
        "img_fake_samples, _=generate_fake_samples(model, latent_dim, n_samples)\n",
        "\n",
        "for i in range(n_samples):\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img_fake_samples[i, :, :, 0], cmap='gray_r')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NtvbK0rM0fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}